{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-time_series",
      "display_name": "Python (env time_series)",
      "language": "python"
    },
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.9.19",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "tags": [
      "deleted-recipe-editor"
    ],
    "customFields": {},
    "creator": "thinhprovc202@gmail.com",
    "createdOn": 1728582459403,
    "modifiedBy": "thinhprovc202@gmail.com"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nfrom dataiku import spark as dkuspark\nfrom pyspark import SparkContext\nfrom pyspark.sql import SQLContext\n\nsc \u003d SparkContext.getOrCreate()\nsqlContext \u003d SQLContext(sc)\n\n# Read recipe inputs\nnorway_new_car_sales_by_make \u003d dataiku.Dataset(\"norway_new_car_sales_by_make\")\nnorway_new_car_sales_by_make_df \u003d dkuspark.get_dataframe(sqlContext, norway_new_car_sales_by_make)\n\n# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a SparkSQL dataframe\ncheck_df \u003d norway_new_car_sales_by_make_df # For this sample code, simply copy input to output\n\n# Write recipe outputs\n#check \u003d dataiku.Dataset(\"check\")\n#dkuspark.write_with_schema(check, check_df)\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\n\n# Tạo Spark session\nspark \u003d SparkSession.builder.appName(\"Create Partitioned Datasets\").getOrCreate()\n\n# Đọc dataset từ Dataiku\ndf \u003d dataiku.Dataset(\"norway_new_car_sales_by_make\").get_dataframe()\n\n# Chuyển đổi DataFrame sang Spark DataFrame\nspark_df \u003d spark.createDataFrame(df)\n\n# Lọc dữ liệu cho năm 2009\ndf_2009 \u003d spark_df.filter(F.col(\u0027Year\u0027) \u003d\u003d 2009)\n\n# Lọc dữ liệu cho năm 2010\ndf_2010 \u003d spark_df.filter(F.col(\u0027Year\u0027) \u003d\u003d 2010)\n\n# Định nghĩa đường dẫn lưu dataset với partition\noutput_path_2009 \u003d \"norway_new_car_sales_by_make_2009\"\noutput_path_2010 \u003d \"norway_new_car_sales_by_make_2010\"\n\n# Lưu dataset cho năm 2009 với partition\ndf_2009.write.partitionBy(\"Year\").format(\"parquet\").mode(\"overwrite\").save(output_path_2009)\n\n# Lưu dataset cho năm 2010 với partition\ndf_2010.write.partitionBy(\"Year\").format(\"parquet\").mode(\"overwrite\").save(output_path_2010)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}